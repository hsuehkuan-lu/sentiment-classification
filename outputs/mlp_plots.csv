epoch,train_loss,dev_loss,learning_rate,fold
1,0.6369278140114125,0.49935693196628406,0.0001,1
2,0.39198375554476383,0.34819622661756433,0.0001,1
1,0.29843129217624664,0.29795024317243823,0.0001,2
2,0.2547100895412878,0.29093298963878467,0.0001,2
1,0.2318921972444092,0.22851312937943832,0.0001,3
2,0.20756058445299305,0.2393644769554553,0.0001,3
1,0.1997111793157559,0.18711075575455374,0.0001,4
2,0.18511005782562753,0.20544645319814267,0.0001,4
1,0.1727472054929549,0.17695567918860394,5e-05,5
2,0.16571051173883936,0.18446877274824225,5e-05,5
1,0.16524343563306734,0.1523437305637028,5e-05,6
2,0.15987959723685674,0.16202614553596661,5e-05,6
1,0.1547270264962445,0.1561545875409375,2.5e-05,7
2,0.1513236223715515,0.1612966025005216,2.5e-05,7
1,0.15033997548519126,0.1321564086753389,1.25e-05,8
2,0.14871415359098555,0.13415733174137448,1.25e-05,8
1,0.14832398637337385,0.13062124796535657,1.25e-05,9
2,0.1465357743239633,0.1325765504785206,1.25e-05,9
1,0.1445509342179782,0.13550656126893085,6.25e-06,10
2,0.14360986534812023,0.13678424384282983,6.25e-06,10
