fold,epoch,train_loss,dev_loss
1,1,0.4897710084915161,0.35252445936203003
1,2,0.2784009575843811,0.3127995729446411
2,1,0.20448388159275055,0.20356766879558563
2,2,0.1483915001153946,0.2292976826429367
3,1,0.13117378950119019,0.11358047276735306
3,2,0.08875902742147446,0.14308808743953705
4,1,0.07947955280542374,0.07085385173559189
4,2,0.05349448695778847,0.09343240410089493
5,1,0.05481692776083946,0.03396574780344963
5,2,0.032945748418569565,0.07475320249795914
6,1,0.036169636994600296,0.017672603949904442
6,2,0.023307327181100845,0.07972782105207443
7,1,0.024668190628290176,0.018859773874282837
7,2,0.013808809220790863,0.046832483261823654
8,1,0.016144879162311554,0.010531446896493435
8,2,0.011740964837372303,0.03780661150813103
9,1,0.016777988523244858,0.0034533292055130005
9,2,0.010476221330463886,0.01532946340739727
10,1,0.010532100684940815,0.0021589347161352634
10,2,0.006289014592766762,0.029165703803300858
