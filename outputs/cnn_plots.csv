epoch,train_loss,dev_loss,learning_rate,fold
1,0.6338224358227338,0.5464487283126168,0.0001,1
2,0.37485970418687087,0.4250643428253091,0.0001,1
3,0.2574665616050728,0.36733905711899634,0.0001,1
1,0.2651249605563421,0.2998057828973169,0.0001,2
2,0.16196774233548777,0.23367857479530832,0.0001,2
3,0.11455436759407579,0.24256577537111615,0.0001,2
1,0.1781310574925563,0.1610229698860127,0.0001,3
2,0.08760329162351767,0.1878346120533736,0.0001,3
3,0.05837298397448076,0.1663480732266022,0.0001,3
1,0.11541902333147804,0.07151869028482748,0.0001,4
2,0.041175398973707485,0.0535307090587752,0.0001,4
3,0.025880890531396895,0.05339851144083735,0.0001,4
1,0.08248813003263555,0.03633114388819946,0.0001,5
2,0.019539109813949563,0.01814347530370983,0.0001,5
3,0.011615749569453266,0.02326703507139388,0.0001,5
