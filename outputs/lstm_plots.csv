epoch,train_loss,dev_loss,learning_rate,fold
1,0.4646577582520954,0.328499397991792,0.0001,1
2,0.30413964197499627,0.5590123060594677,0.0001,1
1,0.25839570868471706,0.2578344944783527,0.0001,2
2,0.22599347758774374,0.25471625541863235,0.0001,2
1,0.2000898946117222,0.1452415078352003,0.0001,3
2,0.17239526995219803,0.19141276818497674,0.0001,3
1,0.13245834050797034,0.11798612634732347,5e-05,4
2,0.11448828687414428,0.12698244573244744,5e-05,4
1,0.10636142361655461,0.24219736162289654,5e-05,5
2,0.08126605200935819,0.15397695934845376,2.5e-05,5
1,0.08359348525581003,0.04206857284905551,2.5e-05,6
2,0.07809284242365375,0.09189202110270422,2.5e-05,6
1,0.06236735780045487,0.041709593848558456,1.25e-05,7
2,0.06199805802153475,0.06051905372521066,1.25e-05,7
1,0.06463270553350582,0.04035525456571992,1.25e-05,8
2,0.0586965548683016,0.06578310520505867,1.25e-05,8
1,0.05437609328938576,0.022348259012292343,6.25e-06,9
2,0.05191702043400732,0.027816738708956425,6.25e-06,9
1,0.0498379988259785,0.028375271500606133,6.25e-06,10
2,0.044538881024552696,0.032039566173688916,3.125e-06,10
