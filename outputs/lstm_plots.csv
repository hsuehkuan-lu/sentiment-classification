epoch,train_loss,dev_loss,learning_rate,fold
1,0.8596528211471495,0.7115868145357007,0.01,1
2,0.7721471486039643,0.8772593428907187,0.01,1
3,0.7228277441753679,0.7024266865590344,0.005,1
1,0.7932684438592407,0.8195602284825366,0.01,2
2,0.7689352950705495,0.8062007083840992,0.01,2
3,0.7729857149825758,0.7502766494517741,0.01,2
1,0.7915753862675919,0.7571776638860288,0.01,3
2,0.7790422792005929,0.7244502092185228,0.01,3
3,0.7676292580707197,0.8538642376661301,0.01,3
1,0.7650469545609945,0.7829332163800364,0.01,4
2,0.7501426421166766,0.7543644542279451,0.01,4
3,0.7313996546924602,0.7429030310848485,0.01,4
1,0.7313864797922182,0.7719874245964963,0.01,5
2,0.7066848708433416,0.6950281877880511,0.01,5
3,0.6914862274555159,0.5567270054117494,0.005,5
