{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "\n",
    "The task is from [aidea](https://aidea-web.tw/topic/c4a666bb-7d83-45a6-8c3b-57514faf2901), the goal is to predict the sentiment of each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41411</td>\n",
       "      <td>I watched this film because I'm a big fan of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37586</td>\n",
       "      <td>It does not seem that this movie managed to pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6017</td>\n",
       "      <td>Enough is not a bad movie , just mediocre .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44656</td>\n",
       "      <td>my friend and i rented this one a few nights a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38711</td>\n",
       "      <td>Just about everything in this movie is wrong, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>8019</td>\n",
       "      <td>It 's one of the most honest films ever made a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>453</td>\n",
       "      <td>An absorbing and unsettling psychological drama .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>13097</td>\n",
       "      <td>Soylent Green IS...a really good movie, actual...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>26896</td>\n",
       "      <td>There just isn't enough here. There a few funn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>27094</td>\n",
       "      <td>This show was absolutely terrible. For one Geo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             review  sentiment\n",
       "0      41411  I watched this film because I'm a big fan of R...          0\n",
       "1      37586  It does not seem that this movie managed to pl...          1\n",
       "2       6017        Enough is not a bad movie , just mediocre .          0\n",
       "3      44656  my friend and i rented this one a few nights a...          0\n",
       "4      38711  Just about everything in this movie is wrong, ...          0\n",
       "...      ...                                                ...        ...\n",
       "29336   8019  It 's one of the most honest films ever made a...          1\n",
       "29337    453  An absorbing and unsettling psychological drama .          1\n",
       "29338  13097  Soylent Green IS...a really good movie, actual...          1\n",
       "29339  26896  There just isn't enough here. There a few funn...          0\n",
       "29340  27094  This show was absolutely terrible. For one Geo...          0\n",
       "\n",
       "[29341 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29341.000000</td>\n",
       "      <td>29341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29348.411097</td>\n",
       "      <td>0.509662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17002.074346</td>\n",
       "      <td>0.499915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14564.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29348.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44162.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58681.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     sentiment\n",
       "count  29341.000000  29341.000000\n",
       "mean   29348.411097      0.509662\n",
       "std    17002.074346      0.499915\n",
       "min        4.000000      0.000000\n",
       "25%    14564.000000      0.000000\n",
       "50%    29348.000000      1.000000\n",
       "75%    44162.000000      1.000000\n",
       "max    58681.000000      1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14954\n",
       "0    14387\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>Robert Lansing plays a scientist experimenting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>Well I've enjoy this movie, even though someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>First things first - though I believe Joel Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>I watched this movie on the grounds that Amber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>A certain sexiness underlines even the dullest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>30370</td>\n",
       "      <td>It is difficult to rate a writer/director's fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>18654</td>\n",
       "      <td>After watching this movie once, it quickly bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>47985</td>\n",
       "      <td>Even though i sat and watched the whole thing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>9866</td>\n",
       "      <td>Warning Spoilers following. Superb recreation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>35559</td>\n",
       "      <td>My, my, my: Peter Cushing and Donald Pleasance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             review\n",
       "0      22622  Robert Lansing plays a scientist experimenting...\n",
       "1      10162  Well I've enjoy this movie, even though someti...\n",
       "2      17468  First things first - though I believe Joel Sch...\n",
       "3      42579  I watched this movie on the grounds that Amber...\n",
       "4        701  A certain sexiness underlines even the dullest...\n",
       "...      ...                                                ...\n",
       "29336  30370  It is difficult to rate a writer/director's fi...\n",
       "29337  18654  After watching this movie once, it quickly bec...\n",
       "29338  47985  Even though i sat and watched the whole thing,...\n",
       "29339   9866  Warning Spoilers following. Superb recreation ...\n",
       "29340  35559  My, my, my: Peter Cushing and Donald Pleasance...\n",
       "\n",
       "[29341 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>30370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>18654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>47985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>9866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>35559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  sentiment\n",
       "0      22622          1\n",
       "1      10162          1\n",
       "2      17468          1\n",
       "3      42579          1\n",
       "4        701          1\n",
       "...      ...        ...\n",
       "29336  30370          1\n",
       "29337  18654          1\n",
       "29338  47985          1\n",
       "29339   9866          1\n",
       "29340  35559          1\n",
       "\n",
       "[29341 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold # import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=123) # Define the split - into 2 folds \n",
    "kf.get_n_splits(train_df) # returns the number of splitting iterations in the cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41411</td>\n",
       "      <td>I watched this film because I'm a big fan of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37586</td>\n",
       "      <td>It does not seem that this movie managed to pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6017</td>\n",
       "      <td>Enough is not a bad movie , just mediocre .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             review  sentiment\n",
       "0  41411  I watched this film because I'm a big fan of R...          0\n",
       "1  37586  It does not seem that this movie managed to pl...          1\n",
       "2   6017        Enough is not a bad movie , just mediocre .          0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 5 6 7 8 9] TEST: [4]\n",
      "9 1\n",
      "TRAIN: [1 2 3 4 5 6 7 8 9] TEST: [0]\n",
      "9 1\n",
      "TRAIN: [0 1 2 3 4 5 6 8 9] TEST: [7]\n",
      "9 1\n",
      "TRAIN: [0 1 2 3 4 6 7 8 9] TEST: [5]\n",
      "9 1\n",
      "TRAIN: [0 1 2 3 4 5 6 7 9] TEST: [8]\n",
      "9 1\n",
      "TRAIN: [0 1 2 4 5 6 7 8 9] TEST: [3]\n",
      "9 1\n",
      "TRAIN: [0 2 3 4 5 6 7 8 9] TEST: [1]\n",
      "9 1\n",
      "TRAIN: [0 1 2 3 4 5 7 8 9] TEST: [6]\n",
      "9 1\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8] TEST: [9]\n",
      "9 1\n",
      "TRAIN: [0 1 3 4 5 6 7 8 9] TEST: [2]\n",
      "9 1\n"
     ]
    }
   ],
   "source": [
    "X, y = train_df, train_df['sentiment'].to_numpy()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for line in train_df['review']:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102969"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 241, 0, 1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[i] for i in ['I', 'am', 'aaaaaaaaaaaaa', '<pad>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(X):\n",
    "    if isinstance(X, list):\n",
    "        return [[vocab[i] for i in tokenizer(text)] for text in X]\n",
    "    return [vocab[i] for i in tokenizer(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 241, 5, 57, 412, 36, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"I am a good boy! ADJISDAKSD unkqwjs <pad> <pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 241, 5, 57], [412, 36]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline([\"I am a good\", \"boy!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "         label_list.append(_label)\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "df = train_df.iloc[:100]\n",
    "train_iter = list(zip(df['review'], df['sentiment']))\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) torch.Size([1882]) torch.Size([8])\n",
      "(tensor([0, 1, 0, 0, 0, 1, 0, 1]), tensor([  13,  295,   14,  ..., 2629, 3377,    3]), tensor([   0,  210,  723,  733,  966, 1203, 1479, 1573]))\n",
      "torch.Size([8]) torch.Size([1716]) torch.Size([8])\n",
      "(tensor([0, 1, 0, 1, 1, 1, 0, 0]), tensor([  45,    2,   87,  ..., 1357, 1252,    3]), tensor([   0,  154,  307,  844,  857, 1055, 1240, 1702]))\n",
      "torch.Size([8]) torch.Size([1589]) torch.Size([8])\n",
      "(tensor([1, 1, 0, 0, 0, 0, 1, 1]), tensor([   95,    90,    31,  ..., 15920, 11537,     3]), tensor([   0,  285,  442,  836, 1132, 1370, 1560, 1577]))\n",
      "torch.Size([8]) torch.Size([1216]) torch.Size([8])\n",
      "(tensor([0, 1, 0, 0, 1, 0, 0, 1]), tensor([   14,    23,    10,  ...,  2445,    82, 13622]), tensor([   0,  149,  329,  544,  559,  776,  997, 1093]))\n",
      "torch.Size([8]) torch.Size([2802]) torch.Size([8])\n",
      "(tensor([0, 1, 1, 1, 0, 1, 1, 0]), tensor([2020, 3173,    4,  ...,    8, 3660,   36]), tensor([   0,  614,  906, 1201, 1258, 2379, 2391, 2663]))\n",
      "torch.Size([8]) torch.Size([1127]) torch.Size([8])\n",
      "(tensor([0, 0, 1, 1, 0, 0, 1, 1]), tensor([   20,    99,  2996,  ...,     3, 17654,     3]), tensor([  0,  23, 112, 128, 158, 234, 525, 849]))\n",
      "torch.Size([8]) torch.Size([1168]) torch.Size([8])\n",
      "(tensor([1, 1, 1, 1, 0, 1, 1, 1]), tensor([    2, 16978,    10,  ...,  1562, 70918,     3]), tensor([   0,  149,  296,  481,  674,  956,  977, 1137]))\n",
      "torch.Size([8]) torch.Size([1286]) torch.Size([8])\n",
      "(tensor([1, 0, 1, 1, 0, 1, 1, 1]), tensor([ 209,  100,    4,  ...,   11,    3, 1934]), tensor([  0,  23,  68, 560, 578, 754, 772, 936]))\n",
      "torch.Size([8]) torch.Size([3302]) torch.Size([8])\n",
      "(tensor([0, 1, 0, 0, 0, 1, 0, 1]), tensor([  14, 1188,   66,  ...,  104,   81,    3]), tensor([   0,  154,  479, 1153, 1289, 1588, 2338, 2361]))\n",
      "torch.Size([8]) torch.Size([2045]) torch.Size([8])\n",
      "(tensor([1, 0, 1, 0, 0, 0, 1, 1]), tensor([   2, 1965,    4,  ...,    3,    3,   55]), tensor([   0,  157,  519,  654,  874, 1335, 1688, 1836]))\n",
      "torch.Size([8]) torch.Size([1603]) torch.Size([8])\n",
      "(tensor([0, 1, 1, 1, 0, 0, 1, 0]), tensor([ 13, 418,   9,  ...,  88, 682,  24]), tensor([   0,  150,  441,  689,  836, 1051, 1232, 1404]))\n",
      "torch.Size([8]) torch.Size([2817]) torch.Size([8])\n",
      "(tensor([1, 0, 0, 1, 0, 1, 0, 0]), tensor([  2,  74,   6,  ...,  72, 421,   3]), tensor([   0,  138, 1020, 1186, 1272, 1949, 2108, 2241]))\n",
      "torch.Size([4]) torch.Size([553]) torch.Size([4])\n",
      "(tensor([1, 0, 0, 0]), tensor([   13,   228,    14,    23,    37,     2,  2942,  2070,    23,  1340,\n",
      "            4,     6,    46,    17,    29,     5,  2387,   831,    12,     2,\n",
      "          339,     3,    11,    10,  1038,     8,    73,    29,    70,    54,\n",
      "            5,    86,   397, 14456,    10,     4,    22,    96,  5493,     2,\n",
      "          375,     7,     2,   705,    10,   104,     6,    37,   148,     5,\n",
      "          196,   610,     3,    11,    91,   105,    78,   110,    96,  2005,\n",
      "         5043,    17,     4,     6,    96,    28,   118,   363,    41,  1397,\n",
      "            8,  4115,     6,  4726,    12,     5,  1166,   103,     4,    39,\n",
      "        14975,     3,   285,    26,   703,    39,    71,   454,    49,     2,\n",
      "         2009,     6,    72,   739,    37,    38,     3,    11,     9,    16,\n",
      "            5,   398,     6,   503,  7213,   297,    74,     3,     3,     3,\n",
      "          198,   133, 19273,    22,    11,     9,    16,    86,     8,    73,\n",
      "           96,  2788,     6,  3334,  2009,     7,   504,    58,    34,     3,\n",
      "            2,   660,  3403,     6, 22591,    71,   203,     8,    78,     6,\n",
      "           71,    75,   172,     8,    89,    20,     2,    74,     3,     3,\n",
      "            3,    11,     9,    16,   147,    13,    67,    33,   233,    64,\n",
      "         3188,   332,    12,    23,   384,     3,    60,   613,     3,  7667,\n",
      "            4,     2,    74,    47,   477,     8,  2072,    28,    19,    65,\n",
      "         1736,   289,     3,     3,     3,    46,    77,   104,   114,   190,\n",
      "           47,  1438,    12,    46,    15,    75,   172,     8,    89,    20,\n",
      "            2,    74,     4,    69,   166,    78,   240,    15,     2,  1495,\n",
      "          705,   167,     9,    27,    71,   127,    54,    39,    77,   402,\n",
      "            4,    48,    47,    15,    11,   149,    33,    85,  6819,     3,\n",
      "            3,     3,    69,    67,    33,    85,     5,  9339,     4,    29,\n",
      "            5,   851,     3,    18,    13,    33,    47,   295,    38,     7,\n",
      "            2,   662,    66,     8,    14,   231,   140,     2,   511,  1297,\n",
      "            3,     3,     3,    13,     9,   251,    33,     8,   141,    15,\n",
      "           14,    17,    40,   237,     2,   257,     4,     6,    13,    47,\n",
      "          489,     8,  3072,   405,    29,     8,   391,    20,    14,    35,\n",
      "            3,    13,    45,  5538,  1578,     9,    16,   129,     4,    13,\n",
      "          267,     2,   218,    53,  1654,  6294,     4,    22,  1643,     9,\n",
      "           27,    25,   246,    24,  1417,    11,     8,     5,   655,     3,\n",
      "            2,    21,    10,     5,   121,   438,    79,    13,    17,   991,\n",
      "            3,    13,    94,     9,    27,   171, 56768,  2496,     4,    47,\n",
      "          377,     3,   615,    19, 27585,  7985,     4,    56,    57,     4,\n",
      "           56,   385,     3,    51,    26,   188,     8,   113,     5,    21,\n",
      "           15,   192,  2496,     4,    22,    10,   170,   159,     4,    73,\n",
      "          829,  1419,     9,    16,     9,  2710,   203, 17033,     9,     3,\n",
      "         3442,    14,   284,     9,    27,    54,    13,   489,     8,    73,\n",
      "            3,    13,  1204,    14,    28,   271,     6,   491,     2,    21,\n",
      "           13,   256,   545,  8704,     6,   679,   138,     2,    21,    19,\n",
      "            5,   562,     3, 12715,    54,    13,   167,     9,    27,    45,\n",
      "          462,    39,    77,  1237,    37,     2,   337,   294,     2, 14274,\n",
      "           17,    71,   660,   447,     2,  4368,    25,   646,    24,   568,\n",
      "            8, 11298,   616,     2,    88,  1609,    80,    30,    17,   660,\n",
      "          595,     2,   426,   498,    28,     2,   271,    17,    71,    88,\n",
      "           54,    13,   125,    45,   462,     2,   212,    40,  1572, 13539,\n",
      "            3,    14,   212,    10,    71,    86,     3,    13,    33,     2,\n",
      "        13872,   736,    43,    14,    21,     3,  1023,     2,   458,   498,\n",
      "           10,    29,    57,     4,    22,    99,   577,    19,    99,    68,\n",
      "            3,   294,     2,    98,    68,    76,    73,     2,  4368,    39,\n",
      "         4726,     5,   441,     7,  4712,     3,   447,   929,    10,  1951,\n",
      "          990,    61,    30,    10,    12,     2,   984,     6,    10,   407,\n",
      "          616,    15,   159,   137,    20,     2, 10416,     3,   595,     2,\n",
      "          421,    42,  1075,    14,    23,    67,  2110,   847,    15,   473,\n",
      "          222,  1991,     3]), tensor([  0, 130, 291, 381]))\n"
     ]
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i[0].shape, i[1].shape, i[2].shape)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the performance of model, the frequently adopted solutions are cross validation and the usage of validation set. Since the size of training samples is small, cross validation would be a more appropriate strategy.\n",
    "\n",
    "1. RNN-based model\n",
    "2. Naive-bayes model\n",
    "3. Bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = list(zip(train_df['review'], train_df['sentiment']))\n",
    "num_class = len(set([label for (text, label) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation 0-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.42s | valid accuracy    0.910 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.770 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.42s | valid accuracy    0.920 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 1-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.43s | valid accuracy    0.980 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.42s | valid accuracy    0.990 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.41s | valid accuracy    0.980 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 2-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.41s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 3-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 4-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.40s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 5-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.940 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.42s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 6-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.42s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.41s | valid accuracy    0.930 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 7-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.40s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 8-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.940 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.940 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.40s | valid accuracy    0.940 \n",
      "-----------------------------------------------------------\n",
      "Cross validation 9-fold\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.41s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.45s | valid accuracy    0.950 \n",
      "-----------------------------------------------------------\n",
      "[0.92, 0.99, 0.93, 0.95, 0.95, 0.94, 0.93, 0.95, 0.94, 0.95]\n",
      "0.945\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 3 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "# train_iter = list(zip(train_df.iloc[:1000]['review'], train_df.iloc[:1000]['sentiment']))\n",
    "\n",
    "X, y = train_df.iloc[:1000]['review'], train_df['sentiment'].iloc[:1000].to_numpy()\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# train_dataset = list(train_iter)\n",
    "# test_dataset = list(test_iter)\n",
    "# num_train = int(len(train_dataset) * 0.95)\n",
    "# split_train_, split_valid_ = \\\n",
    "#     random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "# train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "#                               shuffle=True, collate_fn=collate_batch)\n",
    "# valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "#                               shuffle=True, collate_fn=collate_batch)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "#                              shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "total_acc = []\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(X)):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(f\"Cross validation {idx}-fold\")\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    train_iter = list(zip(X_train, y_train))\n",
    "    valid_iter = list(zip(X_valid, y_valid))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "    valid_dataloader = DataLoader(valid_iter, batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True, collate_fn=collate_batch)\n",
    "    cross_acc = None\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(train_dataloader)\n",
    "        acc = evaluate(valid_dataloader)\n",
    "        if cross_acc is not None and cross_acc > acc:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            cross_acc = acc\n",
    "        print('-' * 59)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "              'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                               time.time() - epoch_start_time,\n",
    "                                                acc))\n",
    "        print('-' * 59)\n",
    "    total_acc += [cross_acc]\n",
    "print(total_acc)\n",
    "print(np.mean(total_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RNN-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
