schema: '2.0'
stages:
  prepare:
    cmd: python -m scripts.prepare
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33430132
    - path: scripts/prepare.py
      md5: 8aabc58263855bc558a233c10ce6f14f
      size: 420
    params:
      params.yaml:
        basic:
          vocab_size: 30000
          min_freq: 3
    outs:
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
  train@mlp:
    cmd: python -m scripts.train mlp
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33400790
    - path: outputs/config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    - path: scripts/train.py
      md5: a26dbdbb00c9071996454e90024d3b79
      size: 3307
    params:
      params.yaml:
        mlp:
          embed_dim: 50
          use_bag: true
          hidden_size: 512
          dropout: 0.1
        train:
          batch_size: 64
          shuffle: true
          epochs: 1
          kfold: 2
          optimizer:
            lr: 0.001
            step_lr: 1.0
            gamma: 0.5
            clip: 0.1
    outs:
    - path: outputs/mlp_checkpoint.pth
      md5: 06be00add740868ed603ab170e41297e
      size: 7162229
    - path: outputs/mlp_plots.csv
      md5: b133aaa37233d39110bdf77864cf3bb5
      size: 115
    - path: outputs/mlp_results.json
      md5: 1770f82c650fb68e0219c8e0c00fa6f6
      size: 85
  train@lstm:
    cmd: python -m scripts.train lstm
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33430132
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    - path: scripts/train.py
      md5: f334da3224ebfb3cbed685f72763a722
      size: 2031
    params:
      params.yaml:
        lstm:
          embed_dim: 50
          use_bag: false
          attention_method: concat
          hidden_size: 512
          n_layers: 2
          dropout: 0.33
    outs:
    - path: outputs/lstm_checkpoint.pth
      md5: e0e3c55b22e84459f3bf585dbbbae576
      size: 48851723
    - path: outputs/lstm_config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/lstm_results.json
      md5: c5cbeeb749aec5163d57aad0fb62d400
      size: 82
  inference@mlp:
    cmd: python -m scripts.inference mlp
    deps:
    - path: data/test.csv
      md5: 8ba62e41af40f5b5f9e9ed83e5ee3f2a
      size: 33679413
    - path: outputs/config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/mlp_checkpoint.pth
      md5: 8e0289f0051204520b01861f605c1cb1
      size: 7162229
    - path: scripts/inference.py
      md5: f00115363b4c630e72c408b62d46d2ba
      size: 1890
    outs:
    - path: outputs/mlp_submission.csv
      md5: 74e10df0b866c0ccf2a1d04be8caae9e
      size: 229245
