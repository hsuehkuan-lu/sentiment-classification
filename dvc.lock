schema: '2.0'
stages:
  prepare:
    cmd: python -m scripts.prepare
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33430132
    - path: scripts/prepare.py
      md5: 88c5db6ca73827fb2053aebf6a7164d3
      size: 258
    params:
      params.yaml:
        basic:
          vocab_size: 30000
          min_freq: 3
    outs:
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
  train:
    cmd: python train.py
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33400790
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    - path: train.py
      md5: bdf52480b52ab8388dc99701d9484244
      size: 1951
    params:
      params.yaml:
        model:
          arch: lstm
          embed_dim: 50
          use_bag: false
          attention_method: concat
          hidden_size: 256
          n_layers: 2
          dropout: 0.33
        train:
          batch_size: 64
          shuffle: true
          epochs: 1
          kfold: 2
          optimizer:
            lr: 0.0001
            step_lr: 1.0
            gamma: 0.1
            clip: 0.1
  train_selected:
    cmd: python train.py
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33400790
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    - path: train.py
      md5: bdf52480b52ab8388dc99701d9484244
      size: 1951
    params:
      params.yaml:
        model:
          arch: lstm
          embed_dim: 50
          use_bag: false
          attention_method: concat
          hidden_size: 256
          n_layers: 2
          dropout: 0.33
        train:
          batch_size: 64
          shuffle: true
          epochs: 1
          kfold: 2
          optimizer:
            lr: 0.0001
            step_lr: 1.0
            gamma: 0.1
            clip: 0.1
    outs:
    - path: outputs/checkpoint.pth
      md5: f70828815944926e1336756a65592c9b
      size: 16943883
    - path: outputs/config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/results.json
      md5: 660e87a57ca5a93b117aa1945c4714c0
      size: 82
  inference:
    cmd: python inference.py
    deps:
    - path: data/test.csv
      md5: 8ba62e41af40f5b5f9e9ed83e5ee3f2a
      size: 33679413
    - path: inference.py
      md5: a9574de67dfa87f65c01c142aea3f943
      size: 1584
    - path: outputs/checkpoint.pth
      md5: f70828815944926e1336756a65592c9b
      size: 16943883
    - path: outputs/config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    outs:
    - path: outputs/submission.csv
      md5: 32459d71b9459c8d45b44bcd9b670ea7
      size: 112
  train@mlp:
    cmd: python -m scripts.train mlp
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33430132
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    - path: scripts/train.py
      md5: b2cb2d5444ba14da8941896bd143c78c
      size: 2033
    params:
      params.yaml:
        mlp:
          embed_dim: 50
          use_bag: true
          hidden_size: 512
          dropout: 0.1
    outs:
    - path: outputs/mlp_checkpoint.pth
      md5: 7477de0089df21c5684b8e420c88398c
      size: 7162229
    - path: outputs/mlp_config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/mlp_results.json
      md5: f168dd5c4aaa61a5b329343a306749f0
      size: 113
  train@lstm:
    cmd: python -m scripts.train lstm
    deps:
    - path: data/train.csv
      md5: d0d12f53a232828404431f2416df09fe
      size: 33430132
    - path: outputs/vocab.plk
      md5: 624acb836dddb480147919b7899fc5a3
      size: 966831
    - path: scripts/train.py
      md5: f334da3224ebfb3cbed685f72763a722
      size: 2031
    params:
      params.yaml:
        lstm:
          embed_dim: 50
          use_bag: false
          attention_method: concat
          hidden_size: 512
          n_layers: 2
          dropout: 0.33
    outs:
    - path: outputs/lstm_checkpoint.pth
      md5: e0e3c55b22e84459f3bf585dbbbae576
      size: 48851723
    - path: outputs/lstm_config.json
      md5: 1d5e2973f00bfaf5547ce2fc59063e62
      size: 57
    - path: outputs/lstm_results.json
      md5: c5cbeeb749aec5163d57aad0fb62d400
      size: 82
